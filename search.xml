<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【机器学习100天】第6天——Logistic回归]]></title>
    <url>%2F2018%2F09%2F05%2FD06-logistic-regression%2F</url>
    <content type="text"><![CDATA[本文已同步至我的GitHub上，欢迎来Fork。项目来源于Siraj Raval。 第6天Logistic回归本节所用数据集此数据集包含了用户的基本信息：用户ID,性别,年龄以及预估薪资。一家汽车公司刚刚推出了他们新型的豪华SUV，我们尝试来预测哪些用户会购买这种全新SUV。数据集的最后一列用来表示用户是否购买。我们将建立一种模型来预测用户是否购买这种SUV，该模型基于年龄和预计薪资两个变量。因此我们选择这两列为特征矩阵。我们尝试寻找用户年龄与预估薪资和是否购买SUV的决定之间的相关性。 0x00 数据预处理导入库123import numpy as npimport matplotlib.pyplot as pltimport pandas as pd 导入数据集123dataset = pd.read_csv('Social_Network_Ads.csv')X = dataset.iloc[:, [2, 3]].values #选择第3、4列(年龄和薪水)y = dataset.iloc[:, 4].values #最后一列为结果 将数据集划分为训练集和测试集12from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) 特征缩放1234from sklearn.preprocessing import StandardScalersc = StandardScaler()X_train = sc.fit_transform(X_train) #对训练数据进行拟合并转化X_test = sc.transform(X_test) #基于现有的对象规则，标准化新的参数 0x01 Logistic回归模型这项任务使用线性模型库，之所以称为线性模型库是因为Logistic回归是一个线性分类器，在二维平面上所有特征被一条直线分为两类。依据Logistic回归类创建一个分类器对象，我们用训练集来拟合此模型。 用训练集拟合Logistic回归模型123from sklearn.linear_model import LogisticRegressionclassifier = LogisticRegression()classifier.fit(X_train, y_train) 0x02 预测测试集结果1y_pred = classifier.predict(X_test) 0x03 评估预测结果经过上述步骤我们预测了测试集结果，现在我们要评估Logistic模型是否正确习得和理解了相关特征。这里引入混淆矩阵(Confusion Matrix)的概念。矩阵每一列代表预测值，每一行代表的是实际的类别(每一行的总数表明实际类别的总数)。这个名字来源于它可以非常容易的表明多个类别是否有混淆(也就是一个class被预测成另一个class)。 生成混淆矩阵12from sklearn.metrics import confusion_matrixcm = confusion_matrix(y_test, y_pred) 可视化123456789101112131415161718from matplotlib.colors import ListedColormapplt.rcParams['font.sans-serif'] = [u'SimHei']plt.rcParams['axes.unicode_minus'] = False #这两行代码使图片能显示中文X_set, y_set = X_train, y_trainX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green')))plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max())for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)plt.title('Logistic回归 (训练集)')plt.xlabel('Age')plt.ylabel('Estimated Salary')plt.legend()plt.show() 12345678910111213141516from matplotlib.colors import ListedColormapX_set, y_set = X_test, y_testX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green')))plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max())for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)plt.title('Logistic回归(测试集)')plt.xlabel('Age')plt.ylabel('Estimated Salary')plt.legend()plt.show() 完整代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import numpy as npimport matplotlib.pyplot as pltimport pandas as pddataset = pd.read_csv('Social_Network_Ads.csv')X = dataset.iloc[:, [2, 3]].valuesy = dataset.iloc[:, 4].valuesfrom sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)from sklearn.preprocessing import StandardScalersc = StandardScaler()X_train = sc.fit_transform(X_train)X_test = sc.transform(X_test)from sklearn.linear_model import LogisticRegressionclassifier = LogisticRegression()classifier.fit(X_train, y_train)y_pred = classifier.predict(X_test)from sklearn.metrics import confusion_matrixcm = confusion_matrix(y_test, y_pred)from matplotlib.colors import ListedColormapplt.rcParams['font.sans-serif'] = [u'SimHei']plt.rcParams['axes.unicode_minus'] = False #这两行代码使图片能显示中文X_set, y_set = X_train, y_trainX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green')))plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max())for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)plt.title('Logistic回归 (训练集)')plt.xlabel('Age')plt.ylabel('Estimated Salary')plt.legend()plt.show()from matplotlib.colors import ListedColormapX_set, y_set = X_test, y_testX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green')))plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max())for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)plt.title('Logistic回归(测试集)')plt.xlabel('Age')plt.ylabel('Estimated Salary')plt.legend()plt.show()]]></content>
      <categories>
        <category>机器学习100天</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【机器学习100天】第3天——多元线性回归]]></title>
    <url>%2F2018%2F09%2F05%2FD03-multiple-linear-regression%2F</url>
    <content type="text"><![CDATA[本文已同步至我的GitHub上，欢迎来Fork。项目来源于Siraj Raval。 第3天多元线性回归 本节所用数据集 0x00 数据预处理导入相关库12import pandas as pdimport numpy as np 导入数据集123dataset = pd.read_csv('50_Startups.csv')X = dataset.iloc[ : , :-1].values #除去最后一列Y = dataset.iloc[ : , 4].values #保存最后一列 编码特征数据1234from sklearn.preprocessing import LabelEncoder, OneHotEncoderX[: , 3] = LabelEncoder().fit_transform(X[ : , 3]) #第4列标签为地点oht = OneHotEncoder(categorical_features = [3])X = oht.fit_transform(X).toarray() 避免虚拟变量陷阱1X = X[: , 1:] 把数据集划分为训练集和测试集12from sklearn.model_selection import train_test_splitX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0) 0x01 用训练集拟合多元线性模型123from sklearn.linear_model import LinearRegressionregressor = LinearRegression()regressor.fit(X_train, Y_train) 0x02 预测测试集结果1y_pred = regressor.predict(X_test) 完整代码如下12345678910111213141516171819202122import pandas as pdimport numpy as npdataset = pd.read_csv('50_Startups.csv')X = dataset.iloc[ : , :-1].valuesY = dataset.iloc[ : , 4].valuesfrom sklearn.preprocessing import LabelEncoder, OneHotEncoderX[: , 3] = LabelEncoder().fit_transform(X[ : , 3])oht = OneHotEncoder(categorical_features = [3])X = oht.fit_transform(X).toarray()X = X[: , 1:]from sklearn.model_selection import train_test_splitX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)from sklearn.linear_model import LinearRegressionregressor = LinearRegression()regressor.fit(X_train, Y_train)y_pred = regressor.predict(X_test)]]></content>
      <categories>
        <category>机器学习100天</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【机器学习100天】第2天——简单线性回归]]></title>
    <url>%2F2018%2F09%2F04%2FD02-simple-linear-regression%2F</url>
    <content type="text"><![CDATA[本文已同步至我的GitHub上，欢迎来Fork。项目来源于Siraj Raval。 第2天简单线性回归 本节所用数据集 0x00 数据预处理12345678910import pandas as pdimport numpy as npimport matplotlib.pyplot as pltdataset = pd.read_csv('studentscores.csv')X = dataset.iloc[ : , : 1].values #X取第1列Y = dataset.iloc[ : , 1].values #Y取第2列from sklearn.model_selection import train_test_splitX_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 1/4, random_state = 0) 0x01 将简单线性回归模型拟合至训练集12from sklearn.linear_model import LinearRegressionregressor = LinearRegression().fit(X_train, Y_train) 0x02 预测结果1Y_pred = regressor.predict(X_test) 0x03 可视化训练结果可视化12plt.scatter(X_train , Y_train, color = 'red')plt.plot(X_train , regressor.predict(X_train), color ='blue') 测试结果可视化12plt.scatter(X_test , Y_test, color = 'red')plt.plot(X_test , regressor.predict(X_test), color ='blue') 完整代码如下12345678910111213141516171819202122import pandas as pdimport numpy as npimport matplotlib.pyplot as pltdataset = pd.read_csv('studentscores.csv')X = dataset.iloc[ : , : 1].valuesY = dataset.iloc[ : , 1].valuesfrom sklearn.model_selection import train_test_splitX_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 1/4, random_state = 0)from sklearn.linear_model import LinearRegressionregressor = LinearRegression()regressor = regressor.fit(X_train, Y_train)Y_pred = regressor.predict(X_test)plt.scatter(X_train , Y_train, color = 'red')plt.plot(X_train , regressor.predict(X_train), color ='blue')plt.scatter(X_test , Y_test, color = 'red')plt.plot(X_test , regressor.predict(X_test), color ='blue')]]></content>
      <categories>
        <category>机器学习100天</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【机器学习100天】第1天——数据预处理]]></title>
    <url>%2F2018%2F09%2F04%2FD01-data-preprocessing%2F</url>
    <content type="text"><![CDATA[本文已同步至我的GitHub上，欢迎来Fork。项目来源于Siraj Raval。 第1天数据预处理&emsp;&emsp;根据上图六个步骤来进行数据预处理。 0x00 导入库12import numpy as npimport pandas as pd 0x01 导入数据集123dataset = pd.read_csv('Data.csv')X = dataset.iloc[ : , : -1].valuesY = dataset.iloc[ : , 3].values iloc函数索引列数据X取除最后一列的数组Y取最后一列 0x02 处理缺失数据1234from sklearn.preprocessing import Imputerimputer = Imputer(missing_values = "NaN", strategy = "mean", axis = 0)imputer = imputer.fit(X[ : , 1:3]) #使用X的第2-3列训练一个Imputer类X[ : , 1:3] = imputer.transform(X[ : , 1:3]) #用imputer对象对X本身进行处理 使用sklearn.preprocessing.Imputer类来处理缺失值，用NaN替代缺失值(NaN为浮点类型) 0x03 编码特征数据12from sklearn.preprocessing import LabelEncoder, OneHotEncoderX[ : , 0] = LabelEncoder().fit_transform(X[ : , 0]) #LabelEncoder将标签标准化为0-标签数-1，fit并将X进行处理 创建虚拟变量12X = OneHotEncoder(categorical_features = [0]).fit_transform(X).toarray()Y = LabelEncoder().fit_transform(Y) onehotencoder将类别之间的距离用向量表示，每个类别之间距离相等categorical_features需要类别的列索引 0x04 将数据集划分为训练集和测试集12from sklearn.model_selection import train_test_splitX_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0) *注：高级sklearn版本中的cross_validation已废弃，转移至model_selection模块中 train_test_split第一个参数表示 被划分的样本特征集 ，第二个参数表示 被划分的样本标签test_size在0-1之间表示样本占比，是整数则表示样本数量random_state表示随机数种子 0x05 特征缩放1234from sklearn.preprocessing import StandardScalersc_X = StandardScaler()X_train = sc_X.fit_transform(X_train)X_test = sc_X.fit_transform(X_test) 特征缩放的目标就是数据规范化，使得特征的范围具有可比性。 完整代码如下12345678910111213141516171819202122232425import numpy as npimport pandas as pddataset = pd.read_csv('Data.csv')X = dataset.iloc[ : , :-1].valuesY = dataset.iloc[ : , 3].valuesfrom sklearn.preprocessing import Imputerimputer = Imputer(missing_values = "NaN", strategy = "mean", axis = 0)imputer = imputer.fit(X[ : , 1:3])X[ : , 1:3] = imputer.transform(X[ : , 1:3])from sklearn.preprocessing import LabelEncoder, OneHotEncoderX[ : , 0] = LabelEncoder().fit_transform(X[ : , 0])X = OneHotEncoder(categorical_features = [0]).fit_transform(X).toarray()Y = LabelEncoder().fit_transform(Y)from sklearn.model_selection import train_test_splitX_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0)from sklearn.preprocessing import StandardScalersc_X = StandardScaler()X_train = sc_X.fit_transform(X_train)X_test = sc_X.fit_transform(X_test)]]></content>
      <categories>
        <category>机器学习100天</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英语摘抄]]></title>
    <url>%2F2018%2F08%2F09%2Fen_study%2F</url>
    <content type="text"><![CDATA[这篇博文记录一些常见的单词和比较好的句子。 单词A 单词 解释 a wide range of 广泛的，渊博的 accessible 易进入的，易达到的，易懂的 account for 导致,解释,对…作出说明,负有责任 apart from 除···之外还包括 appear from nowhere 无处不在 as to with reference to,about aspire 向往，渴望，有志于 autism 自闭症 B 单词 解释 be about sth. 核心内容是 be stricken with 得病，遭受打击 behind the times 落伍 bound for 开往··· break down 突破，克服，分解，情绪失控，抛锚 breakdown 故障损坏，关系破裂 break out 爆发 bring about 导致,引起 C 单词 解释 comply with 遵守 comprise 包括，组成 conscientious 认真的，勤勤恳恳的 consecutive 连续的 conspicuous 显眼的，引人注目的 crack down on 打击，遏制 crook 骗子，不择手段，弯曲(手指) crushing 难熬的，无法忍受的 D 单词 解释 delicate 娇美的,柔和的,易碎的,微妙的,棘手的 deliver 兑现，托送，演讲，解救 demanding 要求高的，很费力的 disperse 分散，驱散 dispose of 处理 disruptive 破坏性的，混乱的 draw on 凭借，利用，时光慢慢老去 dwell upon 思考(不乐意的事) E 单词 解释 effect on engaging 迷人的，有魅力的 except for 除···之外不包括 F 单词 解释 for the time being 眼下，暂时 G 单词 解释 gadget 器械，精巧的玩意 give sb. pause to thought 三思 glow (发)红光，微光，洋溢着，散发出 glowing 热情赞扬的，热情洋溢的 go all out 全力以赴 H 单词 解释 halt 停止前进，活动停止，come to a halt hollow 空心的，空洞的，虚伪的 I 单词 解释 identify with 认同，理解，认为··与···有联系 in the final outcome 最终 incentive stimuli incompetent 不合格的，不称职的，无能力的 ineligible 无资格的，不合格的 influence on inspire 激励,启发，使产生灵感 intellectual 智力的,理智的,知识分子 intelligible 可理解的,明白易懂的 in view of because of,considering impact on implication(for) 影响，暗指 M 单词 解释 marginal 微小的，边缘的，不重要的 make for 奔向 make out 辨认出，看出，把…弄清楚 N 单词 解释 neighbourhood 居住区，街区，在···附近 O 单词 解释 only to do 没想到 once for all 一劳永逸地，一次性地 optimal 最佳的 other than 除了，不同于，绝不是 out of question 不可能 P 单词 解释 passing mood 稍纵即逝的感觉 perspiration 汗水 pilot 试验 pledge 答应，保证 promise(to) 有可能,希望，迹象 promotion 晋升,提升，促销，推广 projection 预计，投射 provenance 起源，出处 R 单词 解释 radical 基本的，彻底的，激进的 rational 理性的，合理的 reliability 可信度 resolve(into) 解决，决心，分解 revolve(around) 围绕，以···为中心 run for 参加···竞选 S 单词 解释 sector 行业，部门，扇形，军事区 selfless 无私的，忘我的 shrewd 精明的;敏锐的;有眼光的;精于盘算的 shrink (away) from 躲开，逃避 so as to 目的是 spontaneous 自发的，自然的 sprawl 扩展，延伸 suspend 暂时停职,暂缓,悬挂 sustain 维持，经受，支持 sway 摇摆，影响左右，hold sway占统治地位 T 单词 解释 take up 占用，开始从事 tap 开发，利用，水龙头 turn out 结果是，变得，关掉 turn up 出现，露面 U 单词 解释 under the sway of 在···支配下 ungrounded 没有根据的 utensil 器皿，用具 utmost 最高程度的，最大努力的 V 单词 解释 verdict 裁决，判断，结论 vigorous 剧烈的，活跃的，有活力的 virtual 几乎，差不多，实际上，虚拟的 W 单词 解释 work out 锻炼，健身，解答，计算 句子 Universities that successfully ride the wave of the change will stike a balance between tradition and technology, forge innovative partnerships and demonstrate value. Those that take the leap to think globally, act locally, capitalize on big data will emerge as industry leaders. It is impossible to confidently predict what will happen should Scotland decide to declare independence. But some factors will come into play. To suggest otherwise would be to deny part of the human condition.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>英语学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WampServer+DVWA搭建本地渗透测试环境]]></title>
    <url>%2F2018%2F08%2F08%2Fthe2nd%2F</url>
    <content type="text"><![CDATA[前言 人生苦短，靶场难觅。DVWA是一款基于PHP和MySQL的Web应用，找不到进行“安全测试”的网站没关系，DVWA帮你解决！我们可以利用搭建好的DVWA环境进行各种渗透测试，话不多说，先搭环境吧。由于DVWA需要PHP集成环境，本文选择WampServer，WampServer是集成了Apache Web服务器、PHP解释器和MySQL数据库的集成安装环境。当然，自己搭建环境也OK。或者国内的PHPStudy一键安装。 OS：Window 10 64bit WampServer下载：http://www.wampserver.com/en/ –根据自己电脑位数选择 DVWA下载：http://www.dvwa.co.uk/ –这里是压缩包 安装WampServer 参考百度经验安装WampServer 安装完后在浏览器地址栏输入127.0.0.1就可以进入WampServer界面。 配置MySQL在浏览器地址栏输入127.0.0.1/phpmyadmin进入MySQL数据库登陆界面。用户名为root，初始密码为空。然后是修改root账户的密码。点击 账户 ，再点击root用户的修改权限即可看到 修改密码 选项，输入两次密码点击 执行 即可。修改密码后用修改过后的密码重新进入127.0.0.1/phpmyadmin即修改成功。 DVWA配置我们将前面下载好的DVWA压缩包解压至WampServer的安装目录里的www目录下，将解压后的文件夹DVWA-master更名为dvwa然后进入wamp64\www\dvwa\config文件夹，将此文件夹下的config.inc.php.dist文件的.dist后缀去掉变成PHP文件，再用文本编辑器打开。找到如下字段，将数据库密码字段改成我们前面设置好的密码。 登陆DVWA在浏览器地址栏输入127.0.0.1/dvwa，输入账号 admin ，密码为 password ，再点击 Create/Reset Datebase 即可初始化DVWA，然后再次登陆即可。 本文结束，敬请关注后续博文。]]></content>
      <categories>
        <category>技术教程</category>
      </categories>
      <tags>
        <tag>渗透</tag>
        <tag>网络安全</tag>
        <tag>Web安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一篇 写在博客搭建完成时]]></title>
    <url>%2F2018%2F08%2F08%2Fthe1st%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;现在是8月9日15时52分，外面大雨如注。在我对博客主题进行了大量的修改后，我终于满(pi)意(bei)了。一直羡慕技术宅有一个自己的站点，上面写着自己牛*哄哄的文章，倒现在我折腾了一天，终于搭建了一个博客，却不知道该写些什么了。&emsp;&emsp;昨天进入到我的Github里，发现fork的一些项目都搁置没怎么看，往下再翻翻在底下看见以前的repo，四五月份的时候没时间没心思去折腾，现在在家倒不如把这个博客重新搭建起来。于是找各种资料，确定用jekyll框架，然后到后面发现是一个大坑，它依赖ruby，我搭建好ruby环境后又出现各种问题，70+m的包下载了一个多小时，看到bash里面的几十B/s的速度很无语。被折腾了一圈之后又重新找框架，然后确定为Hexo，然后选主题，换主题，改主题，增加各种功能。看到静态站点传本地图片又是一个问题，又注册好图床和阿里云。到现在终于弄好了，看着眼前的博客，就像自己的孩子一样，有一个信念，一定要培养好他。&emsp;&emsp;我不太会写东西，写些日记都是流水账，所以以后倒不如写一些读书笔记之类，且不说以飨读者，只要自己满意即可。最后，附上《周易》里的一句话来结尾吧。 天行健，君子以自强不息地势坤，君子以厚德载物]]></content>
  </entry>
</search>
